{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8bc9a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyart\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import cartopy.crs as ccrs\n",
    "from pyproj import Proj, CRS, Transformer\n",
    "import glob\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from scipy.interpolate import griddata\n",
    "from collections import defaultdict\n",
    "from scipy.spatial import KDTree\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date of the data\n",
    "year = '2025'\n",
    "month = '03'\n",
    "day = '14'\n",
    "\n",
    "# The path to the data directory\n",
    "# The data is stored in the following directory structure\n",
    "# /mnt/gws/data/tone-ico_doppler_scanning_cloud_radar/L0/Y2025/M03/D13/\n",
    "# The year, month and day are used to construct the path\n",
    "data='/gws/nopw/j04/tone_ico_gws/data/tone-ico_doppler_scanning_cloud_radar/L0/Y'+year+'/M'+month+'/D'+day+'/*el_18*PPI.LV1.NC'\n",
    "file_list = sorted(glob.glob(data))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddeceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in the raw data and a target grid, extracts reflectivity and regrids to the target grid\n",
    "def extractFields(ds, lat_target, lon_target):\n",
    "    # === Extract reflectivity ===\n",
    "    cze_vars = ['C1ZE45', 'C2ZE45', 'C3ZE45', 'C4ZE45']\n",
    "    range_vars = [var.replace('ZE45', 'Range') for var in cze_vars]\n",
    "    data_list = [ds[var].values for var in cze_vars]\n",
    "    range_list = [ds[var].values for var in range_vars]\n",
    "\n",
    "    # Stack reflectivity and range\n",
    "    data_stacked = np.concatenate(data_list, axis=1)  # (n_az, total_range)\n",
    "    ranges_stacked = np.concatenate(range_list)       # (total_range,)\n",
    "\n",
    "    # Filter low reflectivity\n",
    "    data_stacked[data_stacked < -30] = np.nan\n",
    "\n",
    "    # === Get azimuths ===\n",
    "    n_az = data_stacked.shape[0]\n",
    "    azimuths = np.linspace(0, 2 * np.pi, n_az, endpoint=False)\n",
    "\n",
    "    azimuths_2d, ranges_2d = np.meshgrid(azimuths, ranges_stacked, indexing='ij')\n",
    "    X = ranges_2d * np.cos(azimuths_2d)\n",
    "    Y = ranges_2d * np.sin(azimuths_2d)\n",
    "\n",
    "    # === Polar to lat/lon ===\n",
    "    trollLat = ds['GPSLat'].values.item()\n",
    "    trollLon = ds['GPSLon'].values.item()\n",
    "    crs_centered = CRS.from_proj4(f\"+proj=aeqd +lat_0={trollLat} +lon_0={trollLon} +datum=WGS84 +units=m +no_defs\")\n",
    "    crs_geo = CRS.from_epsg(4326)\n",
    "    transformer = Transformer.from_crs(crs_centered, crs_geo, always_xy=True)\n",
    "    lon, lat = transformer.transform(X, Y)\n",
    "\n",
    "    # === Interpolate reflectivity onto target grid ===\n",
    "    points = np.column_stack((lat.ravel(), lon.ravel()))\n",
    "    values = data_stacked.ravel()\n",
    "    dbz_interp = griddata(points, values, (lat_target, lon_target), method='linear', fill_value=np.nan)\n",
    "\n",
    "    # === Interpolate time onto target grid ===\n",
    "    # Time is in seconds since 2001-01-01 00:00:00\n",
    "    time_array = ds['Time'].values.astype(float)  # shape: (n_az,)\n",
    "    base = np.datetime64('2001-01-01T00:00:00', 's')\n",
    "\n",
    "    # Convert to datetime and then seconds since midnight\n",
    "    absolute_times = base + time_array.astype('timedelta64[s]')\n",
    "    seconds_since_midnight = (absolute_times - absolute_times.astype('datetime64[D]')).astype('timedelta64[s]').astype(float)\n",
    "\n",
    "    # Expand time to match (n_az, n_range)\n",
    "    time_2d = np.repeat(seconds_since_midnight[:, np.newaxis], data_stacked.shape[1], axis=1)\n",
    "\n",
    "    # Interpolate time field onto the same target grid\n",
    "    time_values = time_2d.ravel()\n",
    "    time_interp = griddata(points, time_values, (lat_target, lon_target), method='linear', fill_value=np.nan)\n",
    "\n",
    "    return dbz_interp, time_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e191c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts dbz to snowfall rate - ADJUST A, B (Souverijns et al. 2017) as needed\n",
    "def zToSR(dbz, a, b):\n",
    "    dbz[dbz > 1000] = np.nan\n",
    "    #z = 10 ** (dbz / 10)\n",
    "\n",
    "    rate = (dbz / a) ** (1 / b)\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the target uniform lat/lon grid\n",
    "lat_grid = np.arange(-72.15, -71.85, 0.001)\n",
    "lon_grid = np.arange(2, 3, 0.001)\n",
    "lon_target, lat_target = np.meshgrid(lon_grid, lat_grid)\n",
    "nlon, nlat = len(lon_grid), len(lat_grid)\n",
    "\n",
    "timesteps = len(file_list)\n",
    "\n",
    "timeGrid = np.empty((nlat, nlon, timesteps))\n",
    "dbzGrid = np.empty((nlat, nlon, timesteps))\n",
    "snowGrid = np.empty((nlat, nlon, timesteps))\n",
    "\n",
    "\n",
    "# iterating over all the hourly radar scans during the given day, and storing in a common data structure on a common grid\n",
    "k = 0\n",
    "for file in file_list[:21]:\n",
    "    print(k)\n",
    "    ds = xr.open_dataset(file)\n",
    "    print(k)\n",
    "\n",
    "    # Step 1: Extract reflectivity and time, interpolate to lat/lon\n",
    "    dbz_interp, time_interp = extractFields(ds, lat_target, lon_target)\n",
    "\n",
    "    a = 18\n",
    "    b = 1.1\n",
    "\n",
    "    # Step 2: Convert to snowfall rate\n",
    "    snowfall_rate = zToSR(dbz_interp, a, b)\n",
    "\n",
    "    # Step 3: Populate the (lat x lon x time) arrays for time, dbz, snowfall rate\n",
    "    timeGrid[:, :, k] = time_interp\n",
    "    dbzGrid[:, :, k] = dbz_interp \n",
    "    snowGrid[:, :, k] = snowfall_rate\n",
    "    \n",
    "    k = k + 1\n",
    "\n",
    "# Sort the arrays by time\n",
    "sort_indices = np.argsort(timeGrid, axis=2)\n",
    "\n",
    "timeSort_0314 = np.take_along_axis(timeGrid, sort_indices, axis=2)\n",
    "dbzSort_0314 = np.take_along_axis(dbzGrid, sort_indices, axis=2)\n",
    "snowSort_0314 = np.take_along_axis(snowGrid, sort_indices, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes a definite integral over some bounds with trapezoidal integration\n",
    "def defIntegral(x, y, a, b, axis=-1):\n",
    "\n",
    "   # Move integration axis to the last axis for easier manipulation\n",
    "    x = np.moveaxis(x, axis, -1)\n",
    "    y = np.moveaxis(y, axis, -1)\n",
    "\n",
    "    # Shape info\n",
    "    spatial_shape = x.shape[:-1]\n",
    "    nt = x.shape[-1]\n",
    "\n",
    "    # Prepare an output array for results\n",
    "    result_shape = spatial_shape\n",
    "    result = np.zeros(result_shape)\n",
    "\n",
    "    # For each spatial point, integrate along the last axis over [a,b]\n",
    "    # We'll loop over spatial points (should be vectorized if possible, but this is clear)\n",
    "    it = np.nditer(result, flags=['multi_index'], op_flags=['writeonly'])\n",
    "\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index  # spatial indices\n",
    "\n",
    "        x_line = x[idx]  # 1D array shape (nt,)\n",
    "        y_line = y[idx]  # 1D array shape (nt,)\n",
    "\n",
    "        # Find indices inside the interval\n",
    "        inside = (x_line >= a) & (x_line <= b)\n",
    "\n",
    "        if not np.any(inside):\n",
    "            # No points in interval => integral = 0\n",
    "            it[0] = 0\n",
    "            it.iternext()\n",
    "            continue\n",
    "\n",
    "        # Extract inside points\n",
    "        x_sub = x_line[inside]\n",
    "        y_sub = y_line[inside]\n",
    "\n",
    "        # Interpolate y at the boundaries if needed\n",
    "        if x_sub[0] > a:\n",
    "            y_a = np.interp(a, x_line, y_line)\n",
    "            x_sub = np.insert(x_sub, 0, a)\n",
    "            y_sub = np.insert(y_sub, 0, y_a)\n",
    "\n",
    "        if x_sub[-1] < b:\n",
    "            y_b = np.interp(b, x_line, y_line)\n",
    "            x_sub = np.append(x_sub, b)\n",
    "            y_sub = np.append(y_sub, y_b)\n",
    "\n",
    "        # Compute trapezoidal integral for this spatial point\n",
    "        integral = np.trapz(y_sub, x_sub)\n",
    "\n",
    "        it[0] = integral\n",
    "        it.iternext()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4644222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedAvg(y):\n",
    "    \"\"\"\n",
    "    Compute weighted local averages along axis=2 for a 3D array,\n",
    "    handling NaNs by excluding them and rescaling weights.\n",
    "\n",
    "    - Forward:   (2*y[0] + y[1]) / (sum of weights that are not NaN)\n",
    "    - Central:   (y[i-1] + 2*y[i] + y[i+1]) / (sum of weights that are not NaN)\n",
    "    - Backward:  (y[-2] + 2*y[-1]) / (sum of weights that are not NaN)\n",
    "\n",
    "    Parameters:\n",
    "        y (ndarray): 3D array (nx, ny, nt)\n",
    "\n",
    "    Returns:\n",
    "        avg (ndarray): 3D array of same shape, with local weighted averages\n",
    "    \"\"\"\n",
    "    y = np.asarray(y)\n",
    "    nx, ny, nt = y.shape\n",
    "    avg = np.full_like(y, np.nan, dtype=np.float64)\n",
    "\n",
    "    # Forward difference at index 0\n",
    "    y0 = y[:, :, 0]\n",
    "    y1 = y[:, :, 1]\n",
    "    weights = (~np.isnan(y0)).astype(float) * 2 + (~np.isnan(y1)).astype(float)\n",
    "    vals = np.nan_to_num(y0) * 2 + np.nan_to_num(y1)\n",
    "    avg[:, :, 0] = np.where(weights > 0, vals / weights, np.nan)\n",
    "\n",
    "    # Central differences\n",
    "    for i in range(1, nt - 1):\n",
    "        ym = y[:, :, i - 1]\n",
    "        yc = y[:, :, i]\n",
    "        yp = y[:, :, i + 1]\n",
    "\n",
    "        weights = (\n",
    "            (~np.isnan(ym)).astype(float) +\n",
    "            2 * (~np.isnan(yc)).astype(float) +\n",
    "            (~np.isnan(yp)).astype(float)\n",
    "        )\n",
    "        vals = (\n",
    "            np.nan_to_num(ym) +\n",
    "            2 * np.nan_to_num(yc) +\n",
    "            np.nan_to_num(yp)\n",
    "        )\n",
    "        avg[:, :, i] = np.where(weights > 0, vals / weights, np.nan)\n",
    "\n",
    "    # Backward difference at index -1\n",
    "    y_1 = y[:, :, -1]\n",
    "    y_2 = y[:, :, -2]\n",
    "    weights = (~np.isnan(y_2)).astype(float) + 2 * (~np.isnan(y_1)).astype(float)\n",
    "    vals = np.nan_to_num(y_2) + 2 * np.nan_to_num(y_1)\n",
    "    avg[:, :, -1] = np.where(weights > 0, vals / weights, np.nan)\n",
    "\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyAccum_0314 = weightedAvg(snowSort_0314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1490e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "ax.gridlines(draw_labels=True)\n",
    "ax.set_extent([2, 3, -72.15, -71.85], crs=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "\n",
    "\n",
    "cf = ax.pcolormesh(lon_target, lat_target, hourlyAccum_0314[:, :, 18], vmin=0, vmax=1.0, transform=ccrs.PlateCarree(), cmap='viridis')\n",
    "plt.colorbar(cf, label='Hourly Accumulation (mm)')\n",
    "plt.title(\"Accumulation (mm), 18:00-19:00 March 14\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6153d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464219738\n"
     ]
    }
   ],
   "source": [
    "#file_path = '/gws/nopw/j04/tone_ico_gws/cloudnet/neumayer/radar/20230426_neumayer_mira.nc'\n",
    "modfile_path = '/gws/nopw/j04/tone_ico_gws/cloudnet/troll/era5/8c77d7d4c6e1d8b637bca6cfa6a85450.nc'\n",
    "print(os.path.getsize(modfile_path))\n",
    "#modfile_path = '$HOME/Downloads/adaptor.mars.internal-1632457884.4809508-5958-2-30503582-cddd-4511-a5a8-6594018b4cea.nc'\n",
    "model = nc.Dataset(modfile_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coords of Neumayer III\n",
    "fullGrid = np.array(model.variables['mxtpr'][:, 45:50, 720:740]) * 60 * 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9febe332",
   "metadata": {},
   "outputs": [],
   "source": [
    "eraLat = np.array(model.variables['latitude'][30:60]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "eraLon = np.array(model.variables['longitude'][500:900]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29113cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "ax.gridlines(draw_labels=True)\n",
    "ax.set_extent([2, 3, -72.15, -71.85], crs=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "\n",
    "\n",
    "cf = ax.pcolormesh(eraLon, eraLat, fullGrid[39, :, :], vmin=0, vmax=1.0, transform=ccrs.PlateCarree(), cmap='viridis')\n",
    "plt.colorbar(cf, label='Reflectivity (dBZ)')\n",
    "plt.title(\"Reflectivity (dBZ), 15:00 March 14\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de543b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date of the data\n",
    "year = '2025'\n",
    "month = '04'\n",
    "day = '15'\n",
    "\n",
    "# The path to the data directory\n",
    "# The data is stored in the following directory structure\n",
    "# /mnt/gws/data/tone-ico_doppler_scanning_cloud_radar/L0/Y2025/M03/D13/\n",
    "# The year, month and day are used to construct the path\n",
    "data='/gws/nopw/j04/tone_ico_gws/data/tone-ico_doppler_scanning_cloud_radar/L0/Y'+year+'/M'+month+'/D'+day+'/*el_18*PPI.LV1.NC'\n",
    "file_list = sorted(glob.glob(data))  \n",
    "\n",
    "# generating the target uniform lat/lon grid\n",
    "lat_grid = np.arange(-72.15, -71.85, 0.001)\n",
    "lon_grid = np.arange(2, 3, 0.001)\n",
    "lon_target, lat_target = np.meshgrid(lon_grid, lat_grid)\n",
    "nlon, nlat = len(lon_grid), len(lat_grid)\n",
    "\n",
    "timesteps = len(file_list)\n",
    "\n",
    "timeGrid = np.empty((nlat, nlon, timesteps))\n",
    "dbzGrid = np.empty((nlat, nlon, timesteps))\n",
    "snowGrid = np.empty((nlat, nlon, timesteps))\n",
    "\n",
    "\n",
    "# iterating over all the hourly radar scans during the given day, and storing in a common data structure on a common grid\n",
    "k = 0\n",
    "for file in file_list[:]:\n",
    "    print(k)\n",
    "    ds = xr.open_dataset(file)\n",
    "    print(k)\n",
    "\n",
    "    # Step 1: Extract reflectivity and time, interpolate to lat/lon\n",
    "    dbz_interp, time_interp = extractFields(ds, lat_target, lon_target)\n",
    "\n",
    "    a = 18\n",
    "    b = 1.1\n",
    "\n",
    "    # Step 2: Convert to snowfall rate\n",
    "    snowfall_rate = zToSR(dbz_interp, a, b)\n",
    "\n",
    "    # Step 3: Populate the (lat x lon x time) arrays for time, dbz, snowfall rate\n",
    "    timeGrid[:, :, k] = time_interp\n",
    "    dbzGrid[:, :, k] = dbz_interp \n",
    "    snowGrid[:, :, k] = snowfall_rate\n",
    "    \n",
    "    k = k + 1\n",
    "\n",
    "# Sort the arrays by time\n",
    "sort_indices = np.argsort(timeGrid, axis=2)\n",
    "\n",
    "timeSort_0415 = np.take_along_axis(timeGrid, sort_indices, axis=2)\n",
    "dbzSort_0415 = np.take_along_axis(dbzGrid, sort_indices, axis=2)\n",
    "snowSort_0415 = np.take_along_axis(snowGrid, sort_indices, axis=2)\n",
    "\n",
    "hourlyAccum_0415 = weightedAvg(snowSort_0415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "ax.gridlines(draw_labels=True)\n",
    "ax.set_extent([2, 3, -72.15, -71.85], crs=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "\n",
    "\n",
    "cf = ax.pcolormesh(lon_target, lat_target, hourlyAccum_0415[:, :, 21], vmin=0, vmax=0.5, transform=ccrs.PlateCarree(), cmap='viridis')\n",
    "plt.colorbar(cf, label='Hourly Accumulation (mm)')\n",
    "plt.title(\"Accumulation (mm), 21:00-22:00 April 15\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
